{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# House Price Predictions - Modelling\n",
    "\n",
    "In this notebook we will explore and make predictions on the housing dataset from Kaggle:\\\n",
    "https://www.kaggle.com/c/house-prices-advanced-regression-techniques/\n",
    "\n",
    "\n",
    "* Setup\n",
    "    * Import libraries\n",
    "    * Read the data\n",
    "* Linear Models\n",
    "* Ensemble Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# warnings\n",
    "import warnings\n",
    "def ignore_warn(*args, **kwargs): pass\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.warn = ignore_warn\n",
    "\n",
    "# config\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "# modelling\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.linear_model import LinearRegression, ElasticNet, Ridge, Lasso, Lars, LassoLars, OrthogonalMatchingPursuit, BayesianRidge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Read the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows/cols: 1458 221 train\n",
      "rows/cols: 1459 220 test\n",
      "rows/cols: 2917 221 train+test\n"
     ]
    }
   ],
   "source": [
    "# data frames\n",
    "df_train = pd.read_csv('files/train_processed.csv')\n",
    "df_test = pd.read_csv('files/test_processed.csv')\n",
    "df_all = pd.concat([df_train, df_test])\n",
    "\n",
    "# keep track\n",
    "ntrain = df_train.shape[0]\n",
    "ntest = df_test.shape[0]\n",
    "\n",
    "# print shape\n",
    "print('rows/cols:', df_train.shape[0], df_train.shape[1], 'train')\n",
    "print('rows/cols:', df_test.shape[0], df_test.shape[1], 'test')\n",
    "print('rows/cols:', df_all.shape[0], df_all.shape[1], 'train+test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data frames\n",
    "y_train = df_train['SalePrice'].copy()\n",
    "x_train = df_train.drop(columns='SalePrice')\n",
    "x_test = df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_folds = 10\n",
    "\n",
    "def rmsle_cv(model):\n",
    "    kf = KFold(n_folds, shuffle=True, random_state=42).get_n_splits(x_train.values)\n",
    "    rmse= np.sqrt(-cross_val_score(model, x_train.values, y_train, scoring=\"neg_mean_squared_error\", cv = kf))\n",
    "    return(rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Models\n",
    "\n",
    "* https://www.kaggle.com/serigne/stacked-regressions-top-4-on-leaderboard\n",
    "* https://dataaspirant.com/ensemble-methods-bagging-vs-boosting-difference/\n",
    "* https://www.math.unipd.it/~aiolli/corsi/1213/aa/user_guide-0.12-git.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLS \t score: 0.1181 (0.0163), -- 0.83 seconds\n",
      "Lasso \t score: 0.1087 (0.0145), -- 0.88 seconds\n",
      "Ridge \t score: 0.1130 (0.0156), -- 0.47 seconds\n",
      "ENet \t score: 0.1087 (0.0145), -- 0.99 seconds\n",
      "OMP \t score: 0.1209 (0.0149), -- 0.49 seconds\n",
      "BRidge \t score: 0.1103 (0.0140), -- 0.67 seconds\n"
     ]
    }
   ],
   "source": [
    "pipelines = {\n",
    "    'OLS' : make_pipeline(RobustScaler(), LinearRegression()),\n",
    "    'Lasso' : make_pipeline(RobustScaler(), Lasso(alpha =0.0004, random_state=1)),\n",
    "    'Ridge' : make_pipeline(RobustScaler(), Ridge()),\n",
    "    'ENet' : make_pipeline(RobustScaler(), ElasticNet(alpha=0.0004, l1_ratio=.9, random_state=3)),\n",
    "    'OMP' : make_pipeline(RobustScaler(), OrthogonalMatchingPursuit()),\n",
    "    'BRidge' : BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, compute_score=False, copy_X=True,\n",
    "                fit_intercept=True, lambda_1=1e-06, lambda_2=1e-06, n_iter=300,\n",
    "                normalize=False, tol=0.001, verbose=False)\n",
    "}\n",
    "\n",
    "for p in pipelines:\n",
    "    start_time = time.time()\n",
    "    score = rmsle_cv(pipelines[p])\n",
    "    print(p, \"\\t score: {:.4f} ({:.4f}), -- {:.2f} seconds\".format(score.mean(), score.std(), (time.time() - start_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SalePrice</th>\n",
       "      <th>OLS</th>\n",
       "      <th>Lasso</th>\n",
       "      <th>Ridge</th>\n",
       "      <th>ENet</th>\n",
       "      <th>OMP</th>\n",
       "      <th>BRidge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>208500.0</td>\n",
       "      <td>207931.274627</td>\n",
       "      <td>207986.656335</td>\n",
       "      <td>207531.822215</td>\n",
       "      <td>207981.629749</td>\n",
       "      <td>206803.490856</td>\n",
       "      <td>207060.013826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>181500.0</td>\n",
       "      <td>190253.898623</td>\n",
       "      <td>186242.355286</td>\n",
       "      <td>189615.373760</td>\n",
       "      <td>186110.228709</td>\n",
       "      <td>185178.199740</td>\n",
       "      <td>189273.070410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>223500.0</td>\n",
       "      <td>216601.707826</td>\n",
       "      <td>218113.197724</td>\n",
       "      <td>216498.297819</td>\n",
       "      <td>217764.105511</td>\n",
       "      <td>218006.511226</td>\n",
       "      <td>217406.431589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>140000.0</td>\n",
       "      <td>160230.581472</td>\n",
       "      <td>167299.306272</td>\n",
       "      <td>159441.346321</td>\n",
       "      <td>166817.350196</td>\n",
       "      <td>171675.372005</td>\n",
       "      <td>160372.947173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>250000.0</td>\n",
       "      <td>295189.979321</td>\n",
       "      <td>296177.763687</td>\n",
       "      <td>294668.485665</td>\n",
       "      <td>296023.611429</td>\n",
       "      <td>283148.943478</td>\n",
       "      <td>292535.727878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>143000.0</td>\n",
       "      <td>143989.742715</td>\n",
       "      <td>159230.198782</td>\n",
       "      <td>148069.649912</td>\n",
       "      <td>159213.384335</td>\n",
       "      <td>166648.841369</td>\n",
       "      <td>157013.273196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>307000.0</td>\n",
       "      <td>274448.704261</td>\n",
       "      <td>275627.551304</td>\n",
       "      <td>275827.702055</td>\n",
       "      <td>275587.873291</td>\n",
       "      <td>256190.345223</td>\n",
       "      <td>283060.891416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>200000.0</td>\n",
       "      <td>236704.595485</td>\n",
       "      <td>224369.604928</td>\n",
       "      <td>233243.950952</td>\n",
       "      <td>224363.996905</td>\n",
       "      <td>222382.653537</td>\n",
       "      <td>229647.247360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>129900.0</td>\n",
       "      <td>123877.894089</td>\n",
       "      <td>126375.354986</td>\n",
       "      <td>123561.642019</td>\n",
       "      <td>125962.499243</td>\n",
       "      <td>140626.133740</td>\n",
       "      <td>125978.352191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>118000.0</td>\n",
       "      <td>117346.409247</td>\n",
       "      <td>119249.840148</td>\n",
       "      <td>118264.783452</td>\n",
       "      <td>118972.862089</td>\n",
       "      <td>131509.008173</td>\n",
       "      <td>120922.939123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SalePrice            OLS          Lasso          Ridge           ENet  \\\n",
       "0   208500.0  207931.274627  207986.656335  207531.822215  207981.629749   \n",
       "1   181500.0  190253.898623  186242.355286  189615.373760  186110.228709   \n",
       "2   223500.0  216601.707826  218113.197724  216498.297819  217764.105511   \n",
       "3   140000.0  160230.581472  167299.306272  159441.346321  166817.350196   \n",
       "4   250000.0  295189.979321  296177.763687  294668.485665  296023.611429   \n",
       "5   143000.0  143989.742715  159230.198782  148069.649912  159213.384335   \n",
       "6   307000.0  274448.704261  275627.551304  275827.702055  275587.873291   \n",
       "7   200000.0  236704.595485  224369.604928  233243.950952  224363.996905   \n",
       "8   129900.0  123877.894089  126375.354986  123561.642019  125962.499243   \n",
       "9   118000.0  117346.409247  119249.840148  118264.783452  118972.862089   \n",
       "\n",
       "             OMP         BRidge  \n",
       "0  206803.490856  207060.013826  \n",
       "1  185178.199740  189273.070410  \n",
       "2  218006.511226  217406.431589  \n",
       "3  171675.372005  160372.947173  \n",
       "4  283148.943478  292535.727878  \n",
       "5  166648.841369  157013.273196  \n",
       "6  256190.345223  283060.891416  \n",
       "7  222382.653537  229647.247360  \n",
       "8  140626.133740  125978.352191  \n",
       "9  131509.008173  120922.939123  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SalePrice\n",
    "df = np.expm1(y_train).to_frame()\n",
    "\n",
    "# Prediction Models\n",
    "for p in pipelines:\n",
    "    mfit = pipelines[p].fit(x_train.values, y_train)\n",
    "    pred = mfit.predict(x_train.values)\n",
    "    df[p] = np.expm1(pred)\n",
    "    \n",
    "# view a few rows\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "GBoost = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05,\n",
    "                                   max_depth=4, max_features='sqrt',\n",
    "                                   min_samples_leaf=15, min_samples_split=10, \n",
    "                                   loss='huber', random_state =5)\n",
    "\n",
    "model_xgb = xgb.XGBRegressor(colsample_bytree=0.4603, gamma=0.0468, \n",
    "                             learning_rate=0.05, max_depth=3, \n",
    "                             min_child_weight=1.7817, n_estimators=2200,\n",
    "                             reg_alpha=0.4640, reg_lambda=0.8571,\n",
    "                             subsample=0.5213, silent=1,\n",
    "                             random_state =7, nthread = -1,\n",
    "                             verbosity=0)\n",
    "\n",
    "model_lgb = lgb.LGBMRegressor(objective='regression',num_leaves=5,\n",
    "                              learning_rate=0.05, n_estimators=720,\n",
    "                              max_bin = 55, bagging_fraction = 0.8,\n",
    "                              bagging_freq = 5, feature_fraction = 0.2319,\n",
    "                              feature_fraction_seed=9, bagging_seed=9,\n",
    "                              min_data_in_leaf =6, min_sum_hessian_in_leaf = 11,\n",
    "                             verbosity=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBoost  \t score: 0.1141 (0.0153), -- 85.49 seconds\n",
      "XGBoost \t score: 0.1151 (0.0156), -- 25.12 seconds\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "LGBoost \t score: 0.1146 (0.0164), -- 3.34 seconds\n"
     ]
    }
   ],
   "source": [
    "pipelines = {\n",
    "    'GBoost ' : make_pipeline(RobustScaler(), GBoost),\n",
    "    'XGBoost' : make_pipeline(RobustScaler(), model_xgb),\n",
    "    'LGBoost' : make_pipeline(RobustScaler(), model_lgb)\n",
    "}\n",
    "\n",
    "for p in pipelines:\n",
    "    start_time = time.time()\n",
    "    score = rmsle_cv(pipelines[p])\n",
    "    print(p, \"\\t score: {:.4f} ({:.4f}), -- {:.2f} seconds\".format(score.mean(), score.std(), (time.time() - start_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SalePrice</th>\n",
       "      <th>GBoost</th>\n",
       "      <th>XGBoost</th>\n",
       "      <th>LGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>208500.0</td>\n",
       "      <td>208496.370201</td>\n",
       "      <td>205389.031250</td>\n",
       "      <td>207674.487338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>181500.0</td>\n",
       "      <td>178619.375724</td>\n",
       "      <td>180042.203125</td>\n",
       "      <td>172916.755218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>223500.0</td>\n",
       "      <td>220643.333651</td>\n",
       "      <td>213329.406250</td>\n",
       "      <td>214596.790189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>140000.0</td>\n",
       "      <td>142099.982940</td>\n",
       "      <td>159250.046875</td>\n",
       "      <td>153407.625013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>250000.0</td>\n",
       "      <td>260561.882705</td>\n",
       "      <td>285867.937500</td>\n",
       "      <td>293313.801666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>143000.0</td>\n",
       "      <td>142840.947172</td>\n",
       "      <td>155408.125000</td>\n",
       "      <td>147327.313956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>307000.0</td>\n",
       "      <td>301927.698682</td>\n",
       "      <td>287712.156250</td>\n",
       "      <td>278851.107577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>200000.0</td>\n",
       "      <td>201170.379811</td>\n",
       "      <td>214505.718750</td>\n",
       "      <td>211790.041042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>129900.0</td>\n",
       "      <td>129761.014120</td>\n",
       "      <td>130928.640625</td>\n",
       "      <td>133644.397789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>118000.0</td>\n",
       "      <td>117523.838490</td>\n",
       "      <td>122115.453125</td>\n",
       "      <td>123959.274717</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SalePrice        GBoost         XGBoost        LGBoost\n",
       "0   208500.0  208496.370201  205389.031250  207674.487338\n",
       "1   181500.0  178619.375724  180042.203125  172916.755218\n",
       "2   223500.0  220643.333651  213329.406250  214596.790189\n",
       "3   140000.0  142099.982940  159250.046875  153407.625013\n",
       "4   250000.0  260561.882705  285867.937500  293313.801666\n",
       "5   143000.0  142840.947172  155408.125000  147327.313956\n",
       "6   307000.0  301927.698682  287712.156250  278851.107577\n",
       "7   200000.0  201170.379811  214505.718750  211790.041042\n",
       "8   129900.0  129761.014120  130928.640625  133644.397789\n",
       "9   118000.0  117523.838490  122115.453125  123959.274717"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SalePrice\n",
    "df = np.expm1(y_train).to_frame()\n",
    "\n",
    "# Prediction Models\n",
    "for p in pipelines:\n",
    "    mfit = pipelines[p].fit(x_train.values, y_train)\n",
    "    pred = mfit.predict(x_train.values)\n",
    "    df[p] = np.expm1(pred)\n",
    "    \n",
    "# view a few rows\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stacking Models - Averaged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AveragingModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, models):\n",
    "        self.models = models\n",
    "        \n",
    "    # we define clones of the original models to fit the data in\n",
    "    def fit(self, X, y):\n",
    "        self.models_ = [clone(x) for x in self.models]\n",
    "        \n",
    "        # Train cloned base models\n",
    "        for model in self.models_:\n",
    "            model.fit(X, y)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    #Now we do the predictions for cloned models and average them\n",
    "    def predict(self, X):\n",
    "        predictions = np.column_stack([\n",
    "            model.predict(X) for model in self.models_\n",
    "        ])\n",
    "        return np.mean(predictions, axis=1)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "averaged_models = AveragingModels(models = (ENet, GBoost, KRR, lasso))\n",
    "\n",
    "score = rmsle_cv(averaged_models)\n",
    "print(\" Averaged base models score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stacking Models - Meta model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StackingAveragedModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, base_models, meta_model, n_folds=5):\n",
    "        self.base_models = base_models\n",
    "        self.meta_model = meta_model\n",
    "        self.n_folds = n_folds\n",
    "   \n",
    "    # We again fit the data on clones of the original models\n",
    "    def fit(self, X, y):\n",
    "        self.base_models_ = [list() for x in self.base_models]\n",
    "        self.meta_model_ = clone(self.meta_model)\n",
    "        kfold = KFold(n_splits=self.n_folds, shuffle=True, random_state=156)\n",
    "        \n",
    "        # Train cloned base models then create out-of-fold predictions\n",
    "        # that are needed to train the cloned meta-model\n",
    "        out_of_fold_predictions = np.zeros((X.shape[0], len(self.base_models)))\n",
    "        for i, model in enumerate(self.base_models):\n",
    "            for train_index, holdout_index in kfold.split(X, y):\n",
    "                instance = clone(model)\n",
    "                self.base_models_[i].append(instance)\n",
    "                instance.fit(X[train_index], y[train_index])\n",
    "                y_pred = instance.predict(X[holdout_index])\n",
    "                out_of_fold_predictions[holdout_index, i] = y_pred\n",
    "                \n",
    "        # Now train the cloned  meta-model using the out-of-fold predictions as new feature\n",
    "        self.meta_model_.fit(out_of_fold_predictions, y)\n",
    "        return self\n",
    "   \n",
    "    #Do the predictions of all base models on the test data and use the averaged predictions as \n",
    "    #meta-features for the final prediction which is done by the meta-model\n",
    "    def predict(self, X):\n",
    "        meta_features = np.column_stack([\n",
    "            np.column_stack([model.predict(X) for model in base_models]).mean(axis=1)\n",
    "            for base_models in self.base_models_ ])\n",
    "        return self.meta_model_.predict(meta_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_averaged_models = StackingAveragedModels(base_models = (ENet, GBoost, KRR),\n",
    "                                                 meta_model = lasso)\n",
    "\n",
    "score = rmsle_cv(stacked_averaged_models)\n",
    "print(\"Stacking Averaged models score: {:.4f} ({:.4f})\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stacked Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmsle(y, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_averaged_models.fit(x_train.values, y_train)\n",
    "stacked_train_pred = stacked_averaged_models.predict(x_train.values)\n",
    "#stacked_pred = np.expm1(stacked_averaged_models.predict(test.values))\n",
    "print(rmsle(y_train, stacked_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xgb.fit(x_train, y_train)\n",
    "xgb_train_pred = model_xgb.predict(x_train)\n",
    "#xgb_pred = np.expm1(model_xgb.predict(test))\n",
    "print(rmsle(y_train, xgb_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lgb.fit(x_train, y_train)\n",
    "lgb_train_pred = model_lgb.predict(x_train)\n",
    "#lgb_pred = np.expm1(model_lgb.predict(test.values))\n",
    "print(rmsle(y_train, lgb_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''RMSE on the entire Train data when averaging'''\n",
    "\n",
    "print('RMSLE score on train data:')\n",
    "print(rmsle(y_train,stacked_train_pred*0.70 +\n",
    "               xgb_train_pred*0.15 + lgb_train_pred*0.15 ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ensemble Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble = stacked_pred*0.70 + xgb_pred*0.15 + lgb_pred*0.15"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
